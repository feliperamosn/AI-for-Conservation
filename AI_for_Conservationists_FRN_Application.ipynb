{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Felipe RAMOS NEVES\n",
        "\n",
        "**Candidate for AI Innovation Manager at Conservation International**\n",
        "\n",
        "\n",
        "\n",
        "## AI-Based Image Classification for Conservationists\n",
        "\n",
        "The project involves creating an AI model to classify species in images, helping conservationists monitor biodiversity and identify endangered or invasive species. Using the Hugging Face library, a pre-trained Vision Transformer (ViT) model was applied for image classification. The model, trained on the ImageNet dataset, processes images of animals and plants, providing insights for conservation efforts.\n",
        "\n",
        "### 1) Installing\n",
        "- Transformers library from Hugging Face\n",
        "- Torchvision library from PyTorch (one of the main libraries of deep learning)"
      ],
      "metadata": {
        "id": "UTdrBHFXS3Wf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjbW9fLASitg"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2) Using an AI low-code model to classify an image.  \n",
        "\n",
        "The Hugging Face model used was \"google/vit-base-patch16-224\", which is a model based on the Vision Transformer (ViT) architecture, trained for image classification tasks.\n",
        "\n",
        "ViT is a neural network based on transformers, rather than traditional convolutional networks, and was designed to handle images efficiently and accurately."
      ],
      "metadata": {
        "id": "SVn7lrOFYLzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoFeatureExtractor, AutoModelForImageClassification\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "# Downloading a pre-trained model of vision, for example ViT\n",
        "model_name = \"google/vit-base-patch16-224\"\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)\n",
        "model = AutoModelForImageClassification.from_pretrained(model_name)\n",
        "\n",
        "# Upload an image to test the code\n",
        "url = \"https://www.infoescola.com/wp-content/uploads/2008/05/capivara-119654188-1000x667.jpg\"  # Link to any image - In this example, it's a Capybara, very common in Brazil\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "\n",
        "# Pre-process the image\n",
        "inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
        "\n",
        "# Classifying the image\n",
        "outputs = model(**inputs)\n",
        "logits = outputs.logits\n",
        "predicted_class_idx = logits.argmax(-1).item()\n",
        "\n",
        "# Showing the result\n",
        "print(f\"Predicted class index: {predicted_class_idx}\")\n",
        "\n",
        "from transformers import AutoConfig\n",
        "\n",
        "# Load the model configuration to acess the class mapping\n",
        "config = AutoConfig.from_pretrained(model_name)\n",
        "id2label = config.id2label\n",
        "\n",
        "# Showing the name of the class by the index\n",
        "predicted_class_name = id2label[predicted_class_idx]\n",
        "print(f\"Predicted class name: {predicted_class_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCg5PBlrUaS2",
        "outputId": "7666d6fe-ab8e-4c65-9ba8-c4fcfc6f98ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class index: 337\n",
            "Predicted class name: beaver\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The capybara was identified in the beaver's class.\n",
        "\n",
        "**Project Impact**\n",
        "\n",
        "For conservationists, this project facilitates the automatic analysis of large volumes of images, helping to monitor biodiversity and identify invasive or endangered species. For future expansion, additional features could be added, such as audio analysis for birds or mammals, and integration with maps to track the geographical occurrences of species."
      ],
      "metadata": {
        "id": "pmJhkFxIXKyt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Checking a folder of images and saving a file in .csv with the results"
      ],
      "metadata": {
        "id": "hC8JWheLuR5u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connecting to my Google Drive"
      ],
      "metadata": {
        "id": "OanZwBnXvQvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9K6T4EKVrVQq",
        "outputId": "6232b17a-4f3f-49ae-f3d5-dd3efdbcfb0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "results = []\n",
        "\n",
        "for file_name in os.listdir(\"/content/drive/MyDrive/Geoprocessamento/Fotos\"):\n",
        "    image = Image.open(f\"/content/drive/MyDrive/Geoprocessamento/Fotos/{file_name}\")\n",
        "    inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "    predicted_class_idx = outputs.logits.argmax(-1).item()\n",
        "    predicted_class_name = id2label[predicted_class_idx]\n",
        "    print(f\"Predicted class name: {predicted_class_name}\")\n",
        "    results.append((file_name, predicted_class_idx, predicted_class_name))\n",
        "\n",
        "\n",
        "# Save results in a file .csv\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(results, columns=[\"File Name\", \"Predicted Class Index\", \"Predicted Class Name\"])\n",
        "df.to_csv(\"classification_results.csv\", index=False)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"classification_results.csv\")"
      ],
      "metadata": {
        "id": "NoNWOKUOq5bB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "92954c33-504f-4732-ea62-d18648141a52"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class name: beaver\n",
            "Predicted class name: macaw\n",
            "Predicted class name: macaw\n",
            "Predicted class name: platypus, duckbill, duckbilled platypus, duck-billed platypus, Ornithorhynchus anatinus\n",
            "Predicted class name: seashore, coast, seacoast, sea-coast\n",
            "Predicted class name: green lizard, Lacerta viridis\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_506daeda-9ec7-472a-b438-abf851bd05e5\", \"classification_results.csv\", 421)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zWOzuYTrtb4b"
      }
    }
  ]
}